{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from torchvision import io\n",
    "from typing import Dict\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor, TextIteratorStreamer\n",
    "import sys\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "from qwen_vl_utils import process_vision_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tool_server.tf_eval.utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:26<00:00,  5.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load the model in half-precision on the available device(s)\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"/mnt/petrelfs/songmingyang/songmingyang/model/tool-augment/Qwen2-VL-7B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"/mnt/petrelfs/songmingyang/songmingyang/model/tool-augment/Qwen2-VL-7B-Instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image\n",
    "url = \"/mnt/petrelfs/songmingyang/code/tools/test_imgs/roxy.jpeg\"\n",
    "image = Image.open(url)\n",
    "image_base64=pil_to_base64(image)\n",
    "image_base64 = f\"data:image/jpeg;base64,{image_base64}\"\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": image\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "image_inputs, video_inputs = process_vision_info(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The image is an illustration of an anime-style character. The character has long, flowing blue hair and is wearing a beige coat with a high collar and a black dress underneath. The coat has a brownish hue and features a large, decorative button on the front. The character is holding a large, mechanical-looking sword with a black and silver design. The sword has a long, cylindrical handle and a sharp blade. In the background, there is a floating blue crystal or gemstone, and the character appears to be in a snowy or cold environment, as suggested by the white, snowy landscape and the character's attire. The overall style is\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Preprocess the inputs\n",
    "text_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "# Excepted output: '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Describe this image.<|im_end|>\\n<|im_start|>assistant\\n'\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text_prompt], images=[image], padding=True, return_tensors=\"pt\"\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")\n",
    "# Inference: Generation of the output\n",
    "output_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(inputs.input_ids, output_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    ")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = processor.tokenizer\n",
    "streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True, timeout=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is an illustration of an anime-style character. The character has long, flowing blue hair and is wearing a beige coat with a high collar and a black dress underneath. The coat has a brownish hue and features a large, decorative button on the front. The character is holding a large, mechanical-looking sword with a black and silver design. The sword has a long, cylindrical handle and a sharp blade. In the background, there is a floating blue crystal or gemstone, and the character appears to be in a snowy or cold environment, as suggested by the white, snowy landscape and the character's attire. The overall style is vibrant and detailed, with a focus on the character's expression and the mechanical elements of the sword."
     ]
    }
   ],
   "source": [
    "# Image\n",
    "url = \"/mnt/petrelfs/songmingyang/code/tools/test_imgs/roxy.jpeg\"\n",
    "image = Image.open(url)\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Preprocess the inputs\n",
    "text_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "# Excepted output: '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Describe this image.<|im_end|>\\n<|im_start|>assistant\\n'\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text_prompt], images=[image], padding=True, return_tensors=\"pt\"\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")\n",
    "kwargs = {\n",
    "            **inputs,  # 解包原有的 inputs 字典\n",
    "            \"streamer\":streamer,\n",
    "            'max_new_tokens':1024 # 添加额外的参数\n",
    "    \n",
    "        }\n",
    "thread = Thread(target=model.generate, kwargs=kwargs,)\n",
    "thread.start()\n",
    "\n",
    "for new_text in streamer:\n",
    "    print(new_text, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smoe",
   "language": "python",
   "name": "smoe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
